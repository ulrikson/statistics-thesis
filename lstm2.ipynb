{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd03c80b69efc6c35edf58052dd52e794939bcc5e24ed141d0f365672b2a75355b3",
   "display_name": "Python 3.8.8 64-bit ('venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "# Creating functions\n",
    "All the functions that are used in the fitting and predicting  \n",
    "**Don't need to run** this unless want to generate new output, use the csv file 'lstm_results.csv' instead  \n",
    "Or start from \"plotting\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [(\"var%d(t-%d)\" % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [(\"var%d(t)\" % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [(\"var%d(t+%d)\" % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg\n",
    "\n",
    "\n",
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "    # extract raw values\n",
    "    raw_values = series.values\n",
    "\n",
    "    # transform data to be stationary\n",
    "    diff_values = raw_values\n",
    "    diff_values = diff_values.reshape(len(diff_values), 1)\n",
    "\n",
    "    # rescale values to -1, 1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_values = scaler.fit_transform(diff_values)\n",
    "    scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "\n",
    "    # transform into supervised learning problem X, y\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "\n",
    "    # split into train and test sets\n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "    return scaler, train, test\n",
    "\n",
    "\n",
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    X, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=n_batch, verbose=2, shuffle=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "    # reshape input pattern to [samples, timesteps, features]\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "\n",
    "    # make forecast\n",
    "    forecast = model.predict(X, batch_size=n_batch)\n",
    "\n",
    "    # convert to array\n",
    "    return [x for x in forecast[0, :]]\n",
    "\n",
    "\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq, forecast_len):\n",
    "    forecasts = list()\n",
    "    print(f'Forecast x of {forecast_len}:', end=\" \")\n",
    "    for i in range(forecast_len):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        # make forecast\n",
    "        forecast = forecast_lstm(model, X, n_batch)\n",
    "        # store the forecast\n",
    "        forecasts.append(forecast)\n",
    "\n",
    "        # Printing current status in hundreds\n",
    "        step = i % 100\n",
    "        if step == 0:\n",
    "            print(i, end=\" \")\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "def inverse_transform(series, forecasts, scaler):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "\n",
    "        # create array from forecast\n",
    "        forecast = np.array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "\n",
    "        # invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "\n",
    "        inverted.append(inv_scale)\n",
    "\n",
    "    return inverted"
   ]
  },
  {
   "source": [
    "# Fitting and predicting\n",
    "Outputs a matrix with 63 forecasts for every t 1000 periods ahead  \n",
    "**Don't need to run** this unless want to generate new output, use the csv file 'lstm_results.csv' instead\n",
    "Or start from \"plotting\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Preparing data...\n",
      "Fitting model...\n",
      "Epoch 1/5\n",
      "3360/3360 - 5s - loss: 0.0090\n",
      "Epoch 2/5\n",
      "3360/3360 - 3s - loss: 0.0078\n",
      "Epoch 3/5\n",
      "3360/3360 - 3s - loss: 0.0077\n",
      "Epoch 4/5\n",
      "3360/3360 - 3s - loss: 0.0077\n",
      "Epoch 5/5\n",
      "3360/3360 - 3s - loss: 0.0077\n",
      "Making forecasts...\n",
      "Forecast x of 1000: 0 100 200 300 400 500 600 700 800 900 \n",
      "Inverting forecasts...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "logreturns = \"data/final.csv\"\n",
    "series = pd.read_csv(logreturns, usecols=[\"Exchange.Date\", \"logreturns\"], header=0, index_col=0, squeeze=True)\n",
    "\n",
    "# configure\n",
    "n_lag = 1 # same as ARMA-GARCH\n",
    "n_seq = 63  #  number of periods forecast\n",
    "test_share = 0.25\n",
    "n_test = int(len(series) * test_share)\n",
    "n_epochs = 5\n",
    "n_batch = 1\n",
    "n_neurons = 50\n",
    "forecast_len = 1000\n",
    "\n",
    "print(\"Preparing data...\")\n",
    "scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "\n",
    "print(\"Fitting model...\")\n",
    "model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)\n",
    "\n",
    "print(\"Making forecasts...\")\n",
    "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq, forecast_len)\n",
    "\n",
    "print(\"\\nInverting forecasts...\")\n",
    "forecasts = inverse_transform(series, forecasts, scaler)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "source": [
    "# Generating CSV\n",
    "_**Not recommended to run this chunk**, unless the above \"fitting and predicting\" has been run. Use the csv-file instead. That way, we can be sure to get the same results repeatedly._  \n",
    "Or start from \"plotting\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 done!\n"
     ]
    }
   ],
   "source": [
    "# Creating df that is as alike arch_evaluate as possible\n",
    "original_df = pd.read_csv(\"data/final.csv\", usecols=[\"Exchange.Date\", \"logreturns\", \"Close\"])\n",
    "cross_df = pd.DataFrame(columns=['time', 'Close', 'forecast'])\n",
    "\n",
    "forecast_len = 1000\n",
    "for i in range(forecast_len):\n",
    "    train_size_cv = int(len(original_df) * 0.75) + i\n",
    "    train_cv = original_df[:train_size_cv]\n",
    "    last_train = train_cv['Close'].values[-1]\n",
    "    test_cv = original_df[train_size_cv : len(original_df)]\n",
    "\n",
    "    price_forecasts = np.exp(np.cumsum(forecasts[i]) + math.log(last_train))\n",
    "\n",
    "    for j, forecast in enumerate(price_forecasts):\n",
    "        cross_df = cross_df.append({\n",
    "            'time': i+1,\n",
    "            'forecast': forecast,\n",
    "            'Close': test_cv['Close'].values[j]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    step = i % 100\n",
    "    if step == 0:\n",
    "        print(i, end=\" \")\n",
    "\n",
    "print('done!')\n",
    "cross_df.to_csv('data/lstm_results.csv', index=False)"
   ]
  },
  {
   "source": [
    "# Plotting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating a plot df for t=1\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing original df\n",
    "original_df = pd.read_csv(\"data/final.csv\", usecols=[\"Exchange.Date\", \"logreturns\", \"Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations (same as in predicting)\n",
    "\n",
    "n_lag = 1 # same as ARMA-GARCH\n",
    "n_seq = 63  #  number of periods forecast\n",
    "test_share = 0.25\n",
    "n_test = int(len(original_df) * test_share)\n",
    "n_epochs = 5\n",
    "n_batch = 1\n",
    "n_neurons = 50\n",
    "forecast_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting as date\n",
    "original_df['Exchange.Date'] = original_df['Exchange.Date'].apply(lambda x: date(1900, 1, 1) + timedelta(int(x)))\n",
    "original_df.index = original_df['Exchange.Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning all rows in train df (before forecast) to closing value\n",
    "# This is because this column cannot be empty (and we have no forecasts since it's training data)\n",
    "train_df = original_df[:-n_test].copy()\n",
    "train_df[\"forecast\"] = train_df[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming logreturns back to price\n",
    "\n",
    "lstm_cross_df = pd.read_csv('data/lstm_results.csv')\n",
    "price_forecasts = lstm_cross_df[:63]['forecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a separate dataframe only for forecasts\n",
    "\n",
    "forecast_df = pd.DataFrame(columns=[\"Exchange.Date\", \"Close\", \"logreturns\", \"forecast\"])\n",
    "forecast_df[\"Close\"] = original_df[\"Close\"].values[-n_test : -n_test + n_seq]\n",
    "forecast_df[\"logreturns\"] = original_df[\"logreturns\"].values[-n_test : -n_test + n_seq]\n",
    "forecast_df[\"forecast\"] = price_forecasts\n",
    "forecast_df[\"Exchange.Date\"] = forecast_df.index.map(lambda x: date(2016, 8, 1) + timedelta(int(x)))\n",
    "\n",
    "forecast_df.index = forecast_df[\"Exchange.Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging train and forecast dataframe\n",
    "merged_df = train_df.append(forecast_df, ignore_index=True)"
   ]
  },
  {
   "source": [
    "## Generating plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x141214550>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"302.878125pt\" version=\"1.1\" viewBox=\"0 0 598.4875 302.878125\" width=\"598.4875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-14T15:14:03.989728</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 302.878125 \nL 598.4875 302.878125 \nL 598.4875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 279 \nL 591.2875 279 \nL 591.2875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9f540fae0e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"66.745914\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 3300 -->\n      <g transform=\"translate(54.020914 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"134.202394\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 3325 -->\n      <g transform=\"translate(121.477394 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"201.658873\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 3350 -->\n      <g transform=\"translate(188.933873 293.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"269.115353\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3375 -->\n      <g transform=\"translate(256.390353 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"336.571833\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3400 -->\n      <g transform=\"translate(323.846833 293.598437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"404.028312\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3425 -->\n      <g transform=\"translate(391.303312 293.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"471.484792\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3450 -->\n      <g transform=\"translate(458.759792 293.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"538.941272\" xlink:href=\"#m9f540fae0e\" y=\"279\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 3475 -->\n      <g transform=\"translate(526.216272 293.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mc9be8a59da\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"262.768472\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 520 -->\n      <g transform=\"translate(7.2 266.567691)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"231.375903\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 540 -->\n      <g transform=\"translate(7.2 235.175122)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"199.983335\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 560 -->\n      <g transform=\"translate(7.2 203.782553)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"168.590766\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 580 -->\n      <g transform=\"translate(7.2 172.389985)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"137.198197\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 600 -->\n      <g transform=\"translate(7.2 140.997416)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"105.805628\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 620 -->\n      <g transform=\"translate(7.2 109.604847)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"74.413059\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 640 -->\n      <g transform=\"translate(7.2 78.212278)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"43.020491\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 660 -->\n      <g transform=\"translate(7.2 46.819709)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#mc9be8a59da\" y=\"11.627922\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 680 -->\n      <g transform=\"translate(7.2 15.427141)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p06ca2ffcb9)\" d=\"M 58.651136 205.257286 \nL 61.349396 204.598042 \nL 64.047655 208.192491 \nL 66.745914 217.516084 \nL 69.444173 212.88568 \nL 72.142432 220.969267 \nL 74.840691 252.942598 \nL 77.538951 266.645455 \nL 80.23721 256.113248 \nL 82.935469 261.449984 \nL 85.633728 256.631225 \nL 88.331987 244.262553 \nL 91.030247 244.623568 \nL 93.728506 226.902462 \nL 96.426765 226.44727 \nL 99.125024 228.707535 \nL 101.823283 221.440155 \nL 104.521543 222.680162 \nL 107.219802 231.234637 \nL 109.918061 227.718669 \nL 112.61632 227.828543 \nL 118.012838 216.762663 \nL 123.409357 216.841144 \nL 126.107616 213.780369 \nL 128.805875 213.60771 \nL 131.504134 217.657351 \nL 134.202394 209.605157 \nL 136.900653 209.871994 \nL 139.598912 205.696782 \nL 142.297171 203.766139 \nL 144.99543 204.346902 \nL 147.69369 203.46791 \nL 150.391949 208.694773 \nL 153.090208 204.755005 \nL 155.788467 205.304375 \nL 158.486726 205.006146 \nL 161.184985 198.288136 \nL 163.883245 203.860317 \nL 166.581504 204.425383 \nL 169.279763 198.52358 \nL 171.978022 194.568117 \nL 174.676281 197.566107 \nL 177.374541 196.467367 \nL 180.0728 202.180814 \nL 182.771059 188.917454 \nL 185.469318 203.844621 \nL 188.167577 199.62232 \nL 190.865837 196.07496 \nL 193.564096 195.588375 \nL 196.262355 184.020213 \nL 201.658873 179.107276 \nL 204.357132 173.34674 \nL 207.055392 169.202921 \nL 209.753651 167.554811 \nL 212.45191 172.185215 \nL 215.150169 171.934074 \nL 217.848428 181.194882 \nL 220.546688 185.009079 \nL 223.244947 177.616129 \nL 225.943206 186.751367 \nL 228.641465 198.115477 \nL 231.339724 198.068388 \nL 234.037984 210.829467 \nL 236.736243 212.477577 \nL 239.434502 207.674514 \nL 242.132761 204.048672 \nL 244.83102 207.407677 \nL 247.529279 208.490721 \nL 250.227539 209.322624 \nL 252.925798 205.853745 \nL 255.624057 204.770701 \nL 258.322316 196.184834 \nL 261.020575 196.655722 \nL 263.718835 201.788407 \nL 266.417094 198.586365 \nL 269.115353 198.978772 \nL 271.813612 198.366617 \nL 274.511871 192.872918 \nL 277.210131 190.502779 \nL 279.90839 186.343264 \nL 282.606649 187.959981 \nL 285.304908 185.056168 \nL 288.003167 186.201997 \nL 290.701426 187.818714 \nL 293.399686 191.931141 \nL 296.097945 183.06274 \nL 298.796204 187.426307 \nL 301.494463 187.70884 \nL 304.192722 201.600052 \nL 306.890982 224.061435 \nL 309.589241 244.749138 \nL 312.2875 231.925273 \nL 314.985759 244.906101 \nL 317.684018 234.593642 \nL 320.382278 222.413325 \nL 323.080537 219.493816 \nL 328.477055 212.053777 \nL 331.175314 253.319309 \nL 333.873574 238.36075 \nL 336.571833 225.709545 \nL 341.968351 205.932226 \nL 344.66661 196.3261 \nL 347.364869 196.012175 \nL 350.063129 203.358036 \nL 352.761388 197.989907 \nL 355.459647 190.298727 \nL 358.157906 179.483987 \nL 360.856165 177.082456 \nL 366.252684 161.574527 \nL 368.950943 152.816 \nL 371.649202 137.653389 \nL 374.347461 131.390572 \nL 377.045721 121.59609 \nL 379.74398 121.925712 \nL 382.442239 130.024995 \nL 385.140498 120.010766 \nL 387.838757 116.871509 \nL 390.537016 113.434022 \nL 393.235276 109.761092 \nL 395.933535 103.639541 \nL 398.631794 103.432025 \nL 401.330053 103.105434 \nL 412.12309 99.983134 \nL 417.519608 98.922792 \nL 425.614386 97.573222 \nL 433.709163 96.97551 \nL 436.407423 96.8776 \nL 439.105682 96.934698 \nL 441.803941 96.797509 \nL 447.200459 96.231125 \nL 449.898719 95.910953 \nL 452.596978 95.723563 \nL 455.295237 95.349742 \nL 463.390015 93.931289 \nL 468.786533 92.942033 \nL 474.183051 91.890217 \nL 482.277829 91.276219 \nL 484.976088 91.595049 \nL 487.674347 91.704264 \nL 490.372606 91.972128 \nL 495.769125 92.778402 \nL 501.165643 93.777622 \nL 503.863902 94.603727 \nL 509.260421 95.374554 \nL 514.656939 95.433665 \nL 520.053457 95.671446 \nL 528.148235 95.825688 \nL 530.846494 95.596816 \nL 536.243013 94.856167 \nL 541.639531 93.97737 \nL 544.33779 93.375443 \nL 549.734309 91.65962 \nL 555.130827 89.397723 \nL 563.225604 85.553455 \nL 565.923864 83.859475 \nL 565.923864 83.859475 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#p06ca2ffcb9)\" d=\"M 58.651136 205.257286 \nL 61.349396 204.598042 \nL 64.047655 208.192491 \nL 66.745914 217.516084 \nL 69.444173 212.88568 \nL 72.142432 220.969267 \nL 74.840691 252.942598 \nL 77.538951 266.645455 \nL 80.23721 256.113248 \nL 82.935469 261.449984 \nL 85.633728 256.631225 \nL 88.331987 244.262553 \nL 91.030247 244.623568 \nL 93.728506 226.902462 \nL 96.426765 226.44727 \nL 99.125024 228.707535 \nL 101.823283 221.440155 \nL 104.521543 222.680162 \nL 107.219802 231.234637 \nL 109.918061 227.718669 \nL 112.61632 227.828543 \nL 118.012838 216.762663 \nL 123.409357 216.841144 \nL 126.107616 213.780369 \nL 128.805875 213.60771 \nL 131.504134 217.657351 \nL 134.202394 209.605157 \nL 136.900653 209.871994 \nL 139.598912 205.696782 \nL 142.297171 203.766139 \nL 144.99543 204.346902 \nL 147.69369 203.46791 \nL 150.391949 208.694773 \nL 153.090208 204.755005 \nL 155.788467 205.304375 \nL 158.486726 205.006146 \nL 161.184985 198.288136 \nL 163.883245 203.860317 \nL 166.581504 204.425383 \nL 169.279763 198.52358 \nL 171.978022 194.568117 \nL 174.676281 197.566107 \nL 177.374541 196.467367 \nL 180.0728 202.180814 \nL 182.771059 188.917454 \nL 185.469318 203.844621 \nL 188.167577 199.62232 \nL 190.865837 196.07496 \nL 193.564096 195.588375 \nL 196.262355 184.020213 \nL 201.658873 179.107276 \nL 204.357132 173.34674 \nL 207.055392 169.202921 \nL 209.753651 167.554811 \nL 212.45191 172.185215 \nL 215.150169 171.934074 \nL 217.848428 181.194882 \nL 220.546688 185.009079 \nL 223.244947 177.616129 \nL 225.943206 186.751367 \nL 228.641465 198.115477 \nL 231.339724 198.068388 \nL 234.037984 210.829467 \nL 236.736243 212.477577 \nL 239.434502 207.674514 \nL 242.132761 204.048672 \nL 244.83102 207.407677 \nL 247.529279 208.490721 \nL 250.227539 209.322624 \nL 252.925798 205.853745 \nL 255.624057 204.770701 \nL 258.322316 196.184834 \nL 261.020575 196.655722 \nL 263.718835 201.788407 \nL 266.417094 198.586365 \nL 269.115353 198.978772 \nL 271.813612 198.366617 \nL 274.511871 192.872918 \nL 277.210131 190.502779 \nL 279.90839 186.343264 \nL 282.606649 187.959981 \nL 285.304908 185.056168 \nL 288.003167 186.201997 \nL 290.701426 187.818714 \nL 293.399686 191.931141 \nL 296.097945 183.06274 \nL 298.796204 187.426307 \nL 301.494463 187.70884 \nL 304.192722 201.600052 \nL 306.890982 224.061435 \nL 309.589241 244.749138 \nL 312.2875 231.925273 \nL 314.985759 244.906101 \nL 317.684018 234.593642 \nL 320.382278 222.413325 \nL 323.080537 219.493816 \nL 328.477055 212.053777 \nL 331.175314 253.319309 \nL 333.873574 238.36075 \nL 336.571833 225.709545 \nL 341.968351 205.932226 \nL 344.66661 196.3261 \nL 347.364869 196.012175 \nL 350.063129 203.358036 \nL 352.761388 197.989907 \nL 355.459647 190.298727 \nL 358.157906 179.483987 \nL 360.856165 177.082456 \nL 366.252684 161.574527 \nL 368.950943 152.816 \nL 371.649202 137.653389 \nL 374.347461 131.390572 \nL 377.045721 121.59609 \nL 379.74398 121.925712 \nL 382.442239 130.024995 \nL 385.140498 120.010766 \nL 387.838757 116.871509 \nL 390.537016 113.434022 \nL 393.235276 109.761092 \nL 395.933535 103.639541 \nL 398.631794 101.457757 \nL 401.330053 107.846145 \nL 404.028312 110.326158 \nL 406.726572 103.796504 \nL 409.424831 102.179787 \nL 412.12309 99.370152 \nL 414.821349 97.988879 \nL 417.519608 98.161538 \nL 420.217868 90.344788 \nL 422.916127 85.259192 \nL 425.614386 79.200426 \nL 428.312645 82.575127 \nL 431.010904 89.607063 \nL 433.709163 88.932123 \nL 436.407423 93.232904 \nL 439.105682 80.28347 \nL 441.803941 77.206998 \nL 444.5022 78.556879 \nL 447.200459 79.137641 \nL 449.898719 76.43788 \nL 452.596978 74.318882 \nL 455.295237 71.054055 \nL 457.993496 75.966992 \nL 460.691755 80.079418 \nL 463.390015 75.088 \nL 466.088274 68.260116 \nL 468.786533 64.304652 \nL 471.484792 56.534992 \nL 474.183051 57.712213 \nL 476.88131 59.784122 \nL 479.57957 76.280917 \nL 482.277829 73.047483 \nL 484.976088 68.809486 \nL 487.674347 67.334035 \nL 490.372606 67.522391 \nL 493.070866 65.952762 \nL 498.467384 55.78157 \nL 501.165643 49.691412 \nL 503.863902 49.503056 \nL 506.562162 52.375476 \nL 509.260421 50.350655 \nL 511.95868 46.505066 \nL 514.656939 36.412355 \nL 517.355198 33.335883 \nL 522.751717 23.086209 \nL 525.449976 19.554545 \nL 528.148235 23.808239 \nL 530.846494 26.602177 \nL 533.544753 25.158119 \nL 536.243013 26.20977 \nL 538.941272 37.385525 \nL 541.639531 49.848374 \nL 544.33779 39.598701 \nL 547.036049 44.464549 \nL 549.734309 29.882701 \nL 552.432568 30.212323 \nL 555.130827 24.357608 \nL 557.829086 25.629008 \nL 560.527345 29.176368 \nL 563.225604 30.432071 \nL 565.923864 37.793628 \nL 565.923864 37.793628 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 279 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 591.2875 279 \nL 591.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 279 \nL 591.2875 279 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 591.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 40.2875 44.55625 \nL 112.721875 44.55625 \nQ 114.721875 44.55625 114.721875 42.55625 \nL 114.721875 14.2 \nQ 114.721875 12.2 112.721875 12.2 \nL 40.2875 12.2 \nQ 38.2875 12.2 38.2875 14.2 \nL 38.2875 42.55625 \nQ 38.2875 44.55625 40.2875 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 42.2875 20.298437 \nL 62.2875 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_18\">\n     <!-- forecast -->\n     <g transform=\"translate(70.2875 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"96.386719\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"135.25\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"196.773438\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"251.753906\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"313.033203\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"365.132812\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 42.2875 34.976562 \nL 62.2875 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_19\">\n     <!-- actual -->\n     <g transform=\"translate(70.2875 38.476562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"155.46875\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"218.847656\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"280.126953\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p06ca2ffcb9\">\n   <rect height=\"271.8\" width=\"558\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plot_df = merged_df[-n_seq - (n_seq * 2) :] # -n_seq controls how many to show before the forecast (blue) line\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(plot_df[\"forecast\"], label=\"forecast\")\n",
    "plt.plot(plot_df[\"Close\"], label=\"actual\")\n",
    "plt.legend()"
   ]
  },
  {
   "source": [
    "# Cross-validating 2.0\n",
    "The previous one was messy, this is (hopefully) better. And more like arch_evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Reading CSV and assigning columns\n",
    "_Run this chunk instead, it reads the csv from the chunk above_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading lstm_cross_val.csv\n",
    "lstm_cross_df = pd.read_csv('data/lstm_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding first row of data based on last row of test data (manually input bcuz lazy)\n",
    "\n",
    "new_data = []\n",
    "new_data.insert(0, {'time':0, 'Close': 621.38, 'forecast': 621.38})\n",
    "lstm_cross_df = pd.concat([pd.DataFrame(new_data), lstm_cross_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating error and up columns \n",
    "\n",
    "lstm_cross_df['error'] = lstm_cross_df['forecast'] - lstm_cross_df['Close']\n",
    "lstm_cross_df['abs_error'] = np.abs(lstm_cross_df['forecast'] - lstm_cross_df['Close'])\n",
    "lstm_cross_df['actual_up'] = lstm_cross_df['Close'].diff(1) > 0\n",
    "lstm_cross_df['forecast_up'] = lstm_cross_df['forecast'].diff(1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion column\n",
    "\n",
    "def confusion(actual, forecast):\n",
    "    if (actual and forecast):\n",
    "        return 'TP'\n",
    "    \n",
    "    if (actual and not forecast):\n",
    "        return 'FN'\n",
    "    \n",
    "    if (not actual and forecast):\n",
    "        return 'FP'\n",
    "    \n",
    "    if (not actual and not forecast):\n",
    "        return 'TN'\n",
    "    \n",
    "    return False\n",
    "\n",
    "lstm_cross_df['confusion'] = lstm_cross_df.apply(lambda x: confusion(x['actual_up'], x['forecast_up']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   time   Close    forecast     error  abs_error  actual_up  forecast_up  \\\n",
       "0   0.0  621.38  621.380000  0.000000   0.000000      False        False   \n",
       "1   1.0  622.77  621.512207 -1.257793   1.257793       True         True   \n",
       "2   1.0  618.70  621.720276  3.020276   3.020276      False         True   \n",
       "\n",
       "  confusion  \n",
       "0        TN  \n",
       "1        TP  \n",
       "2        FP  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>Close</th>\n      <th>forecast</th>\n      <th>error</th>\n      <th>abs_error</th>\n      <th>actual_up</th>\n      <th>forecast_up</th>\n      <th>confusion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>621.38</td>\n      <td>621.380000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>TN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>622.77</td>\n      <td>621.512207</td>\n      <td>-1.257793</td>\n      <td>1.257793</td>\n      <td>True</td>\n      <td>True</td>\n      <td>TP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>618.70</td>\n      <td>621.720276</td>\n      <td>3.020276</td>\n      <td>3.020276</td>\n      <td>False</td>\n      <td>True</td>\n      <td>FP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Displaying the first 3 rows\n",
    "# Note that the first row is equal to the last one in the training data\n",
    "\n",
    "lstm_cross_df.head(3)"
   ]
  },
  {
   "source": [
    "## Creating cross evaluation scores for each of the 1000 periods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with all the columns needed\n",
    "\n",
    "cross_df = pd.DataFrame(columns=[\n",
    "    \"mape_1\", \n",
    "    \"mape_3\",\n",
    "    \"mape_5\",\n",
    "    \"mape_21\",\n",
    "    \"mape_63\",\n",
    "    \"rmse_1\",\n",
    "    \"rmse_3\",\n",
    "    \"rmse_5\",\n",
    "    \"rmse_21\",\n",
    "    \"rmse_63\",\n",
    "    'precision_1',\n",
    "    'precision_3',\n",
    "    'precision_5',\n",
    "    'precision_21',\n",
    "    'precision_63',\n",
    "    'recall_1',\n",
    "    'recall_3',\n",
    "    'recall_5',\n",
    "    'recall_21',\n",
    "    'recall_63',\n",
    "    'fscore_1',\n",
    "    'fscore_3',\n",
    "    'fscore_5',\n",
    "    'fscore_21',\n",
    "    'fscore_63',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross evaluation function\n",
    "\n",
    "def cross_evaluate(df, n_periods):\n",
    "    df = df[-63:-63+n_periods] if n_periods < 63 else df.tail(63)\n",
    "    mape = ((df[\"abs_error\"] / df[\"Close\"]).sum() / n_periods) * 100\n",
    "    rmse = math.sqrt(pow(df[\"error\"].sum(), 2) / n_periods)\n",
    "\n",
    "    tp = len(df[df['confusion'] == 'TP'])\n",
    "    fp = len(df[df['confusion'] == 'FP'])\n",
    "    fn = len(df[df['confusion'] == 'FN'])\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0 # if else för att undvika division by zero errror\n",
    "    recall = tp / (tp + fn) if (tp + fn > 0) else 0\n",
    "    fscore = (2*precision*recall)/(precision+recall) if (precision + recall > 0) else 0\n",
    "\n",
    "    return mape, rmse, precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 done!\n"
     ]
    }
   ],
   "source": [
    "# For every 63 forecasts of the 1000 periods forecasted, create scores\n",
    "\n",
    "forecast_len = 1000\n",
    "for i in range(forecast_len):\n",
    "    cross_merged_df = lstm_cross_df[i+1 : i+63+1] # to avoid first row 1 is added (which contains last training)\n",
    "    one = cross_evaluate(cross_merged_df, 1)\n",
    "    three = cross_evaluate(cross_merged_df, 3)\n",
    "    five = cross_evaluate(cross_merged_df, 5)\n",
    "    twentyone = cross_evaluate(cross_merged_df, 21)\n",
    "    sixtythree = cross_evaluate(cross_merged_df, 63)\n",
    "\n",
    "    cross_df = cross_df.append({\n",
    "        'mape_1': one[0],\n",
    "        'mape_3': three[0],\n",
    "        'mape_5': five[0],\n",
    "        'mape_21': twentyone[0],\n",
    "        'mape_63': sixtythree[0],\n",
    "        'rmse_1': one[1],\n",
    "        'rmse_3': three[1],\n",
    "        'rmse_5': five[1],\n",
    "        'rmse_21': twentyone[1],\n",
    "        'rmse_63': sixtythree[1],\n",
    "        'precision_1': one[2],\n",
    "        'precision_3': three[2],\n",
    "        'precision_5': five[2],\n",
    "        'precision_21': twentyone[2],\n",
    "        'precision_63': sixtythree[2],\n",
    "        'recall_1': one[3],\n",
    "        'recall_3': three[3],\n",
    "        'recall_5': five[3],\n",
    "        'recall_21': twentyone[3],\n",
    "        'recall_63': sixtythree[3],\n",
    "        'fscore_1': one[4],\n",
    "        'fscore_3': three[4],\n",
    "        'fscore_5': five[4],\n",
    "        'fscore_21': twentyone[4],\n",
    "        'fscore_63': sixtythree[4],\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    step = i % 100\n",
    "    if step == 0:\n",
    "        print(i, end=\" \")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        mape_1    mape_3    mape_5   mape_21   mape_63    rmse_1     rmse_3  \\\n",
       "0     0.201967  0.504992  0.379448  0.987203  3.214610  1.257793   3.956436   \n",
       "1     0.488165  0.514957  0.351570  1.092370  3.222289  3.020276   5.514308   \n",
       "2     0.824842  0.402369  0.283151  1.158756  3.230307  5.090266   4.310935   \n",
       "3     0.231863  0.148280  0.133705  1.187106  3.223104  1.440520   1.146597   \n",
       "4     0.150403  0.119683  0.251526  1.265447  3.223522  0.935972   0.212164   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "1023  0.062574  0.095420  0.476271  1.377048  3.221292  0.390527   1.032556   \n",
       "1024  0.146072  0.348218  0.831295  1.508465  3.221831  0.912922   3.792484   \n",
       "1025  0.077615  0.724237  1.098448  1.668651  3.220381  0.484990   7.922534   \n",
       "1026  0.820967  1.310930  1.234045  1.824319  3.232272  5.170862  14.400518   \n",
       "1027  1.274128  1.531219  1.232337  1.934336  3.240329  8.066379  16.846074   \n",
       "\n",
       "         rmse_5    rmse_21     rmse_63  ...  recall_1  recall_3  recall_5  \\\n",
       "0      4.127442  24.123572  165.417608  ...       1.0       1.0       1.0   \n",
       "1      4.515295  27.226812  164.724582  ...       0.0       1.0       1.0   \n",
       "2      2.756315  30.510589  164.332848  ...       0.0       1.0       1.0   \n",
       "3      0.262985  33.593619  164.683701  ...       1.0       1.0       1.0   \n",
       "4      2.693715  36.527658  164.662759  ...       1.0       1.0       1.0   \n",
       "...         ...        ...         ...  ...       ...       ...       ...   \n",
       "1023   6.719689  40.236380  164.772863  ...       1.0       1.0       1.0   \n",
       "1024  11.779759  44.132477  164.799676  ...       1.0       1.0       1.0   \n",
       "1025  15.578287  48.922514  164.727722  ...       0.0       1.0       1.0   \n",
       "1026  17.491332  53.568284  165.322654  ...       1.0       1.0       1.0   \n",
       "1027  17.470549  56.876774  165.730886  ...       1.0       1.0       1.0   \n",
       "\n",
       "      recall_21  recall_63  fscore_1  fscore_3  fscore_5  fscore_21  fscore_63  \n",
       "0      0.923077   0.621622       1.0       0.5  0.750000   0.727273   0.554217  \n",
       "1      0.923077   0.611111       0.0       0.5  0.750000   0.727273   0.543210  \n",
       "2      0.923077   0.611111       0.0       0.8  0.888889   0.727273   0.543210  \n",
       "3      0.923077   0.621622       1.0       1.0  0.888889   0.727273   0.560976  \n",
       "4      0.923077   0.621622       1.0       1.0  0.888889   0.727273   0.560976  \n",
       "...         ...        ...       ...       ...       ...        ...        ...  \n",
       "1023   0.923077   0.621622       1.0       0.8  0.888889   0.727273   0.560976  \n",
       "1024   0.923077   0.621622       1.0       0.8  0.888889   0.727273   0.560976  \n",
       "1025   0.923077   0.611111       0.0       0.8  0.750000   0.727273   0.543210  \n",
       "1026   0.923077   0.621622       1.0       1.0  0.750000   0.727273   0.560976  \n",
       "1027   0.916667   0.621622       1.0       0.8  0.750000   0.687500   0.560976  \n",
       "\n",
       "[1028 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mape_1</th>\n      <th>mape_3</th>\n      <th>mape_5</th>\n      <th>mape_21</th>\n      <th>mape_63</th>\n      <th>rmse_1</th>\n      <th>rmse_3</th>\n      <th>rmse_5</th>\n      <th>rmse_21</th>\n      <th>rmse_63</th>\n      <th>...</th>\n      <th>recall_1</th>\n      <th>recall_3</th>\n      <th>recall_5</th>\n      <th>recall_21</th>\n      <th>recall_63</th>\n      <th>fscore_1</th>\n      <th>fscore_3</th>\n      <th>fscore_5</th>\n      <th>fscore_21</th>\n      <th>fscore_63</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.201967</td>\n      <td>0.504992</td>\n      <td>0.379448</td>\n      <td>0.987203</td>\n      <td>3.214610</td>\n      <td>1.257793</td>\n      <td>3.956436</td>\n      <td>4.127442</td>\n      <td>24.123572</td>\n      <td>165.417608</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.621622</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.750000</td>\n      <td>0.727273</td>\n      <td>0.554217</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.488165</td>\n      <td>0.514957</td>\n      <td>0.351570</td>\n      <td>1.092370</td>\n      <td>3.222289</td>\n      <td>3.020276</td>\n      <td>5.514308</td>\n      <td>4.515295</td>\n      <td>27.226812</td>\n      <td>164.724582</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.611111</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.750000</td>\n      <td>0.727273</td>\n      <td>0.543210</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.824842</td>\n      <td>0.402369</td>\n      <td>0.283151</td>\n      <td>1.158756</td>\n      <td>3.230307</td>\n      <td>5.090266</td>\n      <td>4.310935</td>\n      <td>2.756315</td>\n      <td>30.510589</td>\n      <td>164.332848</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.611111</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>0.888889</td>\n      <td>0.727273</td>\n      <td>0.543210</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.231863</td>\n      <td>0.148280</td>\n      <td>0.133705</td>\n      <td>1.187106</td>\n      <td>3.223104</td>\n      <td>1.440520</td>\n      <td>1.146597</td>\n      <td>0.262985</td>\n      <td>33.593619</td>\n      <td>164.683701</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.621622</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.888889</td>\n      <td>0.727273</td>\n      <td>0.560976</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.150403</td>\n      <td>0.119683</td>\n      <td>0.251526</td>\n      <td>1.265447</td>\n      <td>3.223522</td>\n      <td>0.935972</td>\n      <td>0.212164</td>\n      <td>2.693715</td>\n      <td>36.527658</td>\n      <td>164.662759</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.621622</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.888889</td>\n      <td>0.727273</td>\n      <td>0.560976</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1023</th>\n      <td>0.062574</td>\n      <td>0.095420</td>\n      <td>0.476271</td>\n      <td>1.377048</td>\n      <td>3.221292</td>\n      <td>0.390527</td>\n      <td>1.032556</td>\n      <td>6.719689</td>\n      <td>40.236380</td>\n      <td>164.772863</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.621622</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.888889</td>\n      <td>0.727273</td>\n      <td>0.560976</td>\n    </tr>\n    <tr>\n      <th>1024</th>\n      <td>0.146072</td>\n      <td>0.348218</td>\n      <td>0.831295</td>\n      <td>1.508465</td>\n      <td>3.221831</td>\n      <td>0.912922</td>\n      <td>3.792484</td>\n      <td>11.779759</td>\n      <td>44.132477</td>\n      <td>164.799676</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.621622</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.888889</td>\n      <td>0.727273</td>\n      <td>0.560976</td>\n    </tr>\n    <tr>\n      <th>1025</th>\n      <td>0.077615</td>\n      <td>0.724237</td>\n      <td>1.098448</td>\n      <td>1.668651</td>\n      <td>3.220381</td>\n      <td>0.484990</td>\n      <td>7.922534</td>\n      <td>15.578287</td>\n      <td>48.922514</td>\n      <td>164.727722</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.611111</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>0.750000</td>\n      <td>0.727273</td>\n      <td>0.543210</td>\n    </tr>\n    <tr>\n      <th>1026</th>\n      <td>0.820967</td>\n      <td>1.310930</td>\n      <td>1.234045</td>\n      <td>1.824319</td>\n      <td>3.232272</td>\n      <td>5.170862</td>\n      <td>14.400518</td>\n      <td>17.491332</td>\n      <td>53.568284</td>\n      <td>165.322654</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.923077</td>\n      <td>0.621622</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.750000</td>\n      <td>0.727273</td>\n      <td>0.560976</td>\n    </tr>\n    <tr>\n      <th>1027</th>\n      <td>1.274128</td>\n      <td>1.531219</td>\n      <td>1.232337</td>\n      <td>1.934336</td>\n      <td>3.240329</td>\n      <td>8.066379</td>\n      <td>16.846074</td>\n      <td>17.470549</td>\n      <td>56.876774</td>\n      <td>165.730886</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.916667</td>\n      <td>0.621622</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.750000</td>\n      <td>0.687500</td>\n      <td>0.560976</td>\n    </tr>\n  </tbody>\n</table>\n<p>1028 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# First three rows of evaluation df\n",
    "\n",
    "cross_df.head(3)"
   ]
  },
  {
   "source": [
    "## Description of RMSE and MAPE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            mape_1       mape_3       mape_5      mape_21      mape_63  \\\n",
       "count  1028.000000  1028.000000  1028.000000  1028.000000  1028.000000   \n",
       "mean      4.373895     4.383518     4.389879     4.441827     4.506782   \n",
       "std       2.599337     2.515984     2.452626     1.920318     0.530896   \n",
       "min       0.009942     0.053727     0.133705     0.987203     3.214610   \n",
       "25%       2.095244     2.173957     2.277333     2.758497     4.289996   \n",
       "50%       4.309314     4.267938     4.224582     4.348099     4.579749   \n",
       "75%       6.826728     6.775895     6.729007     6.112511     4.758490   \n",
       "max       9.471340     9.246645     9.203336     8.695548     5.441038   \n",
       "\n",
       "            rmse_1       rmse_3       rmse_5      rmse_21      rmse_63  \n",
       "count  1028.000000  1028.000000  1028.000000  1028.000000  1028.000000  \n",
       "mean     28.885451    50.021169    64.576789   133.711325   235.149782  \n",
       "std      17.562773    29.569869    37.297423    60.044555    28.903889  \n",
       "min       0.062048     0.212164     0.262985    24.123572   164.332848  \n",
       "25%      13.346184    24.092163    32.535057    81.558493   221.976164  \n",
       "50%      28.068580    48.039488    61.291887   130.540848   238.883298  \n",
       "75%      45.414138    78.238234   100.310972   185.623502   249.406216  \n",
       "max      63.926807   107.835976   138.287243   266.232616   284.728040  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mape_1</th>\n      <th>mape_3</th>\n      <th>mape_5</th>\n      <th>mape_21</th>\n      <th>mape_63</th>\n      <th>rmse_1</th>\n      <th>rmse_3</th>\n      <th>rmse_5</th>\n      <th>rmse_21</th>\n      <th>rmse_63</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n      <td>1028.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.373895</td>\n      <td>4.383518</td>\n      <td>4.389879</td>\n      <td>4.441827</td>\n      <td>4.506782</td>\n      <td>28.885451</td>\n      <td>50.021169</td>\n      <td>64.576789</td>\n      <td>133.711325</td>\n      <td>235.149782</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.599337</td>\n      <td>2.515984</td>\n      <td>2.452626</td>\n      <td>1.920318</td>\n      <td>0.530896</td>\n      <td>17.562773</td>\n      <td>29.569869</td>\n      <td>37.297423</td>\n      <td>60.044555</td>\n      <td>28.903889</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.009942</td>\n      <td>0.053727</td>\n      <td>0.133705</td>\n      <td>0.987203</td>\n      <td>3.214610</td>\n      <td>0.062048</td>\n      <td>0.212164</td>\n      <td>0.262985</td>\n      <td>24.123572</td>\n      <td>164.332848</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.095244</td>\n      <td>2.173957</td>\n      <td>2.277333</td>\n      <td>2.758497</td>\n      <td>4.289996</td>\n      <td>13.346184</td>\n      <td>24.092163</td>\n      <td>32.535057</td>\n      <td>81.558493</td>\n      <td>221.976164</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.309314</td>\n      <td>4.267938</td>\n      <td>4.224582</td>\n      <td>4.348099</td>\n      <td>4.579749</td>\n      <td>28.068580</td>\n      <td>48.039488</td>\n      <td>61.291887</td>\n      <td>130.540848</td>\n      <td>238.883298</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.826728</td>\n      <td>6.775895</td>\n      <td>6.729007</td>\n      <td>6.112511</td>\n      <td>4.758490</td>\n      <td>45.414138</td>\n      <td>78.238234</td>\n      <td>100.310972</td>\n      <td>185.623502</td>\n      <td>249.406216</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.471340</td>\n      <td>9.246645</td>\n      <td>9.203336</td>\n      <td>8.695548</td>\n      <td>5.441038</td>\n      <td>63.926807</td>\n      <td>107.835976</td>\n      <td>138.287243</td>\n      <td>266.232616</td>\n      <td>284.728040</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "cross_df.iloc[:, :10].describe()"
   ]
  },
  {
   "source": [
    "## Description of precision, recall and fscore"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       precision_1  precision_3  precision_5  precision_21  precision_63  \\\n",
       "count  1000.000000  1000.000000  1000.000000   1000.000000   1000.000000   \n",
       "mean      0.164000     0.196333     0.219350      0.350167      0.423575   \n",
       "std       0.370461     0.317890     0.306587      0.263210      0.100251   \n",
       "min       0.000000     0.000000     0.000000      0.000000      0.142857   \n",
       "25%       0.000000     0.000000     0.000000      0.000000      0.333333   \n",
       "50%       0.000000     0.000000     0.000000      0.355042      0.428571   \n",
       "75%       0.000000     0.333333     0.400000      0.545455      0.500000   \n",
       "max       1.000000     1.000000     1.000000      1.000000      0.625000   \n",
       "\n",
       "          recall_1     recall_3     recall_5    recall_21    recall_63  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.164000     0.306000     0.360183     0.332612     0.277223   \n",
       "std       0.370461     0.449641     0.452552     0.313194     0.173626   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.060606   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.151515   \n",
       "50%       0.000000     0.000000     0.000000     0.250000     0.205882   \n",
       "75%       0.000000     1.000000     1.000000     0.571429     0.393939   \n",
       "max       1.000000     1.000000     1.000000     1.000000     0.710526   \n",
       "\n",
       "          fscore_1     fscore_3     fscore_5    fscore_21    fscore_63  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.164000     0.223067     0.244477     0.297654     0.320595  \n",
       "std       0.370461     0.336877     0.315178     0.235218     0.138486  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.085106  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.204082  \n",
       "50%       0.000000     0.000000     0.000000     0.300000     0.285714  \n",
       "75%       0.000000     0.500000     0.571429     0.476190     0.448276  \n",
       "max       1.000000     1.000000     1.000000     0.848485     0.627907  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision_1</th>\n      <th>precision_3</th>\n      <th>precision_5</th>\n      <th>precision_21</th>\n      <th>precision_63</th>\n      <th>recall_1</th>\n      <th>recall_3</th>\n      <th>recall_5</th>\n      <th>recall_21</th>\n      <th>recall_63</th>\n      <th>fscore_1</th>\n      <th>fscore_3</th>\n      <th>fscore_5</th>\n      <th>fscore_21</th>\n      <th>fscore_63</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.164000</td>\n      <td>0.196333</td>\n      <td>0.219350</td>\n      <td>0.350167</td>\n      <td>0.423575</td>\n      <td>0.164000</td>\n      <td>0.306000</td>\n      <td>0.360183</td>\n      <td>0.332612</td>\n      <td>0.277223</td>\n      <td>0.164000</td>\n      <td>0.223067</td>\n      <td>0.244477</td>\n      <td>0.297654</td>\n      <td>0.320595</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.370461</td>\n      <td>0.317890</td>\n      <td>0.306587</td>\n      <td>0.263210</td>\n      <td>0.100251</td>\n      <td>0.370461</td>\n      <td>0.449641</td>\n      <td>0.452552</td>\n      <td>0.313194</td>\n      <td>0.173626</td>\n      <td>0.370461</td>\n      <td>0.336877</td>\n      <td>0.315178</td>\n      <td>0.235218</td>\n      <td>0.138486</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.060606</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.085106</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.151515</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.204082</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.355042</td>\n      <td>0.428571</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.205882</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>0.285714</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.400000</td>\n      <td>0.545455</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.571429</td>\n      <td>0.393939</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.571429</td>\n      <td>0.476190</td>\n      <td>0.448276</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.625000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.710526</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.848485</td>\n      <td>0.627907</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "cross_df.iloc[:, 10:].describe()"
   ]
  },
  {
   "source": [
    "## Confidence intervals for RMSE, MAPE, precision, recall and fscore"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         measure        mean       lower       upper\n",
       "0         mape_1    4.486102    4.328316    4.643889\n",
       "1         mape_3    4.493116    4.340495    4.645737\n",
       "2         mape_5    4.500745    4.352381    4.649109\n",
       "3        mape_21    4.532705    4.416987    4.648423\n",
       "4        mape_63    4.542762    4.512261    4.573263\n",
       "5         rmse_1   29.630396   28.562947   30.697845\n",
       "6         rmse_3   51.297579   49.502668   53.092491\n",
       "7         rmse_5   66.239037   63.980385   68.497688\n",
       "8        rmse_21  136.556364  132.938800  140.173927\n",
       "9        rmse_63  237.115203  235.455694  238.774712\n",
       "10   precision_1    0.164000    0.141039    0.186961\n",
       "11   precision_3    0.196333    0.176630    0.216036\n",
       "12   precision_5    0.219350    0.200348    0.238352\n",
       "13  precision_21    0.350167    0.333853    0.366481\n",
       "14  precision_63    0.423575    0.417362    0.429789\n",
       "15      recall_1    0.164000    0.141039    0.186961\n",
       "16      recall_3    0.306000    0.278131    0.333869\n",
       "17      recall_5    0.360183    0.332134    0.388233\n",
       "18     recall_21    0.332612    0.313200    0.352024\n",
       "19     recall_63    0.277223    0.266462    0.287985\n",
       "20      fscore_1    0.164000    0.141039    0.186961\n",
       "21      fscore_3    0.223067    0.202187    0.243946\n",
       "22      fscore_5    0.244477    0.224942    0.264012\n",
       "23     fscore_21    0.297654    0.283075    0.312233\n",
       "24     fscore_63    0.320595    0.312011    0.329178"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>measure</th>\n      <th>mean</th>\n      <th>lower</th>\n      <th>upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mape_1</td>\n      <td>4.486102</td>\n      <td>4.328316</td>\n      <td>4.643889</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mape_3</td>\n      <td>4.493116</td>\n      <td>4.340495</td>\n      <td>4.645737</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mape_5</td>\n      <td>4.500745</td>\n      <td>4.352381</td>\n      <td>4.649109</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mape_21</td>\n      <td>4.532705</td>\n      <td>4.416987</td>\n      <td>4.648423</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mape_63</td>\n      <td>4.542762</td>\n      <td>4.512261</td>\n      <td>4.573263</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>rmse_1</td>\n      <td>29.630396</td>\n      <td>28.562947</td>\n      <td>30.697845</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>rmse_3</td>\n      <td>51.297579</td>\n      <td>49.502668</td>\n      <td>53.092491</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>rmse_5</td>\n      <td>66.239037</td>\n      <td>63.980385</td>\n      <td>68.497688</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>rmse_21</td>\n      <td>136.556364</td>\n      <td>132.938800</td>\n      <td>140.173927</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>rmse_63</td>\n      <td>237.115203</td>\n      <td>235.455694</td>\n      <td>238.774712</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>precision_1</td>\n      <td>0.164000</td>\n      <td>0.141039</td>\n      <td>0.186961</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>precision_3</td>\n      <td>0.196333</td>\n      <td>0.176630</td>\n      <td>0.216036</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>precision_5</td>\n      <td>0.219350</td>\n      <td>0.200348</td>\n      <td>0.238352</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>precision_21</td>\n      <td>0.350167</td>\n      <td>0.333853</td>\n      <td>0.366481</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>precision_63</td>\n      <td>0.423575</td>\n      <td>0.417362</td>\n      <td>0.429789</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>recall_1</td>\n      <td>0.164000</td>\n      <td>0.141039</td>\n      <td>0.186961</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>recall_3</td>\n      <td>0.306000</td>\n      <td>0.278131</td>\n      <td>0.333869</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>recall_5</td>\n      <td>0.360183</td>\n      <td>0.332134</td>\n      <td>0.388233</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>recall_21</td>\n      <td>0.332612</td>\n      <td>0.313200</td>\n      <td>0.352024</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>recall_63</td>\n      <td>0.277223</td>\n      <td>0.266462</td>\n      <td>0.287985</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>fscore_1</td>\n      <td>0.164000</td>\n      <td>0.141039</td>\n      <td>0.186961</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>fscore_3</td>\n      <td>0.223067</td>\n      <td>0.202187</td>\n      <td>0.243946</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>fscore_5</td>\n      <td>0.244477</td>\n      <td>0.224942</td>\n      <td>0.264012</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>fscore_21</td>\n      <td>0.297654</td>\n      <td>0.283075</td>\n      <td>0.312233</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>fscore_63</td>\n      <td>0.320595</td>\n      <td>0.312011</td>\n      <td>0.329178</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "n = cross_df.count()[0]\n",
    "mean = cross_df.mean()\n",
    "upper = cross_df.mean() + 1.96 * cross_df.std() / math.sqrt(n)\n",
    "lower = cross_df.mean() - 1.96 * cross_df.std() / math.sqrt(n)\n",
    "\n",
    "ci_df = pd.DataFrame(columns=['measure', 'mean', 'lower', 'upper'])\n",
    "\n",
    "for i in range(25):\n",
    "    ci_df = ci_df.append({\n",
    "        'measure': cross_df.columns[i],\n",
    "        'mean': mean[i],\n",
    "        'lower': lower[i],\n",
    "        'upper': upper[i]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "ci_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}