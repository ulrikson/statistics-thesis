{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "3c80b69efc6c35edf58052dd52e794939bcc5e24ed141d0f365672b2a75355b3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "source": [
    "# Creating functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform series into train and test sets for supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform series into train and test sets for supervised learning\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "\t# extract raw values\n",
    "\traw_values = series.values\n",
    "\t\n",
    "    # transform data to be stationary\n",
    "\tdiff_values = raw_values\n",
    "\tdiff_values = diff_values.reshape(len(diff_values), 1)\n",
    "\t\n",
    "    # rescale values to -1, 1\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaled_values = scaler.fit_transform(diff_values)\n",
    "\tscaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "\t\n",
    "    # transform into supervised learning problem X, y\n",
    "\tsupervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "\tsupervised_values = supervised.values\n",
    "\t\n",
    "    # split into train and test sets\n",
    "\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "\treturn scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    X, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=n_batch, verbose=2, shuffle=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one forecast with an LSTM,\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "    # reshape input pattern to [samples, timesteps, features]\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    \n",
    "    # make forecast\n",
    "    forecast = model.predict(X, batch_size=n_batch)\n",
    "    \n",
    "    # convert to array\n",
    "    return [x for x in forecast[0, :]]\n",
    " \n",
    "# evaluate the persistence model\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "    forecasts = list()\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        # make forecast\n",
    "        forecast = forecast_lstm(model, X, n_batch)\n",
    "        # store the forecast\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        \n",
    "        # create array from forecast\n",
    "        forecast = np.array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        \n",
    "        # invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "\n",
    "        inverted.append(inv_scale)\n",
    "\n",
    "    return inverted"
   ]
  },
  {
   "source": [
    "# Fitting and predicting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "logreturns = 'data/final.csv'\n",
    "series = pd.read_csv(logreturns, usecols=['Exchange.Date', 'logreturns'], header=0, index_col=0, squeeze=True)\n",
    "\n",
    "# configure\n",
    "n_lag = 1\n",
    "n_seq = 90 #  number of periods forecast\n",
    "test_share = 0.25\n",
    "n_test = int(len(series) * test_share)\n",
    "n_epochs = 5\n",
    "n_batch = 1\n",
    "n_neurons = 50\n",
    "\n",
    "# prepare data\n",
    "scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "\n",
    "# fit model\n",
    "model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)\n",
    "\n",
    "# make forecasts\n",
    "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n",
    "\n",
    "# inverse transform forecasts and test\n",
    "forecasts = inverse_transform(series, forecasts, scaler)"
   ]
  },
  {
   "source": [
    "# Evaluating from t=1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Close  logreturns    forecast      error  actual_change  \\\n",
       "3423  622.77    0.002234  621.905334  -0.864666           True   \n",
       "3424  618.70   -0.006557  622.373718   3.673718          False   \n",
       "3425  617.12   -0.002557  623.175537   6.055537          False   \n",
       "3426  621.28    0.006718  623.923645   2.643645           True   \n",
       "3427  622.31    0.001656  624.617188   2.307188           True   \n",
       "...      ...         ...         ...        ...            ...   \n",
       "3508  688.99   -0.007850  657.322327 -31.667673          False   \n",
       "3509  688.94   -0.000073  658.048645 -30.891355          False   \n",
       "3510  692.89    0.005717  658.999084 -33.890916           True   \n",
       "3511  694.34    0.002090  659.983704 -34.356296           True   \n",
       "3512  694.06   -0.000403  661.151978 -32.908022          False   \n",
       "\n",
       "      forecast_change  correct  \n",
       "3423             True     True  \n",
       "3424             True    False  \n",
       "3425             True    False  \n",
       "3426             True     True  \n",
       "3427             True     True  \n",
       "...               ...      ...  \n",
       "3508             True    False  \n",
       "3509             True    False  \n",
       "3510             True     True  \n",
       "3511             True     True  \n",
       "3512             True    False  \n",
       "\n",
       "[90 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Close</th>\n      <th>logreturns</th>\n      <th>forecast</th>\n      <th>error</th>\n      <th>actual_change</th>\n      <th>forecast_change</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3423</th>\n      <td>622.77</td>\n      <td>0.002234</td>\n      <td>621.905334</td>\n      <td>-0.864666</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3424</th>\n      <td>618.70</td>\n      <td>-0.006557</td>\n      <td>622.373718</td>\n      <td>3.673718</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3425</th>\n      <td>617.12</td>\n      <td>-0.002557</td>\n      <td>623.175537</td>\n      <td>6.055537</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3426</th>\n      <td>621.28</td>\n      <td>0.006718</td>\n      <td>623.923645</td>\n      <td>2.643645</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3427</th>\n      <td>622.31</td>\n      <td>0.001656</td>\n      <td>624.617188</td>\n      <td>2.307188</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>688.99</td>\n      <td>-0.007850</td>\n      <td>657.322327</td>\n      <td>-31.667673</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3509</th>\n      <td>688.94</td>\n      <td>-0.000073</td>\n      <td>658.048645</td>\n      <td>-30.891355</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3510</th>\n      <td>692.89</td>\n      <td>0.005717</td>\n      <td>658.999084</td>\n      <td>-33.890916</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3511</th>\n      <td>694.34</td>\n      <td>0.002090</td>\n      <td>659.983704</td>\n      <td>-34.356296</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3512</th>\n      <td>694.06</td>\n      <td>-0.000403</td>\n      <td>661.151978</td>\n      <td>-32.908022</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# Creating a merged df with original values and predictions\n",
    "original_df = pd.read_csv('data/final.csv', usecols=['logreturns', 'Close'])\n",
    "train_df = original_df[:-n_test].copy()\n",
    "\n",
    "last_train = train_df['Close'].values[-1]\n",
    "price_forecasts = np.exp(np.cumsum(forecasts[0]) + math.log(last_train))\n",
    "\n",
    "train_df['forecast'] = train_df['Close'] # temporary until actual forecasts are added\n",
    "\n",
    "eval_df = pd.DataFrame(columns=['Close', 'logreturns', 'forecast'])\n",
    "eval_df['Close'] = original_df['Close'].values[-n_test:-n_test+n_seq]\n",
    "eval_df['logreturns'] = original_df['logreturns'].values[-n_test:-n_test+n_seq]\n",
    "eval_df['forecast'] = price_forecasts\n",
    "\n",
    "merged_df = train_df.append(eval_df, ignore_index=True)\n",
    "merged_df['error'] = merged_df['forecast'] - merged_df['Close']\n",
    "\n",
    "merged_df['actual_change'] = merged_df['Close'].diff(1) > 0\n",
    "merged_df['forecast_change'] = merged_df['forecast'].diff(1) > 0\n",
    "\n",
    "def correct(actual, forecast):\n",
    "    if ((actual and forecast) or (not actual and not forecast)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "merged_df['correct'] = merged_df.apply(lambda x: correct(x['actual_change'], x['forecast_change']), axis=1)\n",
    "\n",
    "merged_df.tail(n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1, 25],\n",
       "       [ 0, 37]])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# RMSE and MAE\n",
    "def new_df(n_periods):\n",
    "    df = merged_df[len(train_df):len(train_df)+n_periods]\n",
    "    return df\n",
    "\n",
    "def evaluate(n_periods):\n",
    "    df = new_df(n_periods)\n",
    "    mape = np.mean(np.abs((df['error']) / df['Close'])) * 100\n",
    "    rmse = math.sqrt(pow(df['error'].sum(), 2) / n_periods)\n",
    "    perc_correct = (len(df[df['correct'] == True]) / len(df))*100\n",
    "    print(f\"{n_periods}, RMSE: {round(rmse, 3)}, MAPE: {round(mape, 3)}%, Correct: {round(perc_correct, 3)}%\")\n",
    "\n",
    "# evaluate(1) # 1 day\n",
    "# evaluate(3) # half a week\n",
    "# evaluate(5) # week\n",
    "# evaluate(21) # month\n",
    "# evaluate(63) # quarter\n",
    "\n",
    "df = new_df(63)\n",
    "confusion_matrix(df['actual_change'], df['forecast_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = merged_df[-n_seq - (n_seq*2) :]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(plot_df['forecast'], label=\"forecast\")\n",
    "plt.plot(plot_df['Close'], label=\"actual\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['forecast'].values[0]\n",
    "eval_df['forecast'].values[-1]\n",
    "\n",
    "pred = eval_df['forecast'].values[-1] / eval_df['Close'].values[0]\n",
    "act = eval_df['Close'].values[-1] / eval_df['Close'].values[0]\n",
    "\n",
    "print(pred, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}